---
title: "Homework 5"
author: "Shen Jialun 16307110030"
date: "10/28/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
cat("\014");rm(list=ls())
```

## 1-6.4
Suppose $X_1,...,X_n$ are a random sample from a lognormal($\mu,\sigma^2$) distribution with unknown parameters. 

Let $Y_i = {\rm log}X_i,i=1,...,n$, then $Y_1,...,Y_n$ follows a N($\mu,\sigma^2$) distribution.

$S^2 = \frac{1}{n-1}\sum_{i=1}^n(Y_i-\bar Y)^2$ is an unbiased estimator for $\sigma^2$. And
$$
\frac{\bar Y-\mu}{S/\sqrt n}\sim t(n-1)
$$
Hence, a $(1-\alpha)$ confidence interval for the parametr $\mu$ is
$$
\Bigg[
\bar Y - \frac{S}{\sqrt n}t_{\alpha/2}(n-1),\
\bar Y + \frac{S}{\sqrt n}t_{\alpha/2}(n-1)
\Bigg]
$$
Using MC method, an empirical estimate for the confidence level can be calculated by
```{r}
n <- 20
alpha <- 0.05
calCI <- function(n, alpha){
  x <- rlnorm(n, meanlog = 0, sdlog = 1)
  y <- log(x)
  y.bar <- mean(y)
  y.sd <- sqrt(n/(n-1)*var(y))
  z <- y.sd / sqrt(n) * qt(alpha/2, df = n-1) #Lower alpha/2 quantile
  return (c(y.bar+z, y.bar-z))
}
m <- 1000
CI <- matrix(0, ncol = 2, nrow = m)
cnt <- 0
for (i in 1:m){
  CI[i,] <- calCI(n, alpha)
  if ((CI[i,1]<0) & (CI[i,2]>0)){
    cnt <- cnt + 1
  }
}
cnt/m
```

which is close to the nominal level.

## 1-6.9
```{r}
gini <- function(x){
  x <- sort(x)
  mu <- mean(x)
  n <- length(x)
  g <- 0
  for (i in 1:n){
    g <- g + (2*i-n-1) * x[i]
  }
  g <- g / (n^2 * mu)
  return (g)
}
n <- 100
m <- 1000 #replicates
#standard lognormal
G.hat <- replicate(m, expr = {
  x <- rlnorm(n, meanlog = 0, sdlog = 1)
  gini(x)
})
mean(G.hat)
median(G.hat)
quantile(G.hat, seq(0.1,1,0.1)) #deciles
hist(G.hat, main = "Gini ratio estimation for standard lognormal dist(m=1000)")
#uniform
G.hat <- replicate(m, expr = {
  x <- runif(n)
  gini(x)
})
mean(G.hat)
median(G.hat)
quantile(G.hat, seq(0.1,1,0.1)) #deciles
hist(G.hat, main = "Gini ratio estimation for uniform dist(m=1000)")
#Bernouli(0.1)
G.hat <- replicate(m, expr = {
  x <- sample(c(0,1), size=n, replace=TRUE, prob=c(0.9,0.1))
  gini(x)
})
mean(G.hat)
median(G.hat)
quantile(G.hat, seq(0.1,1,0.1)) #deciles
hist(G.hat, main = "Gini ratio estimation for Bernouli(0.1) dist(m=1000)")
```

## 1-6.10
Let $\{x_1,...,x_n\}$ be an _iid_ sample from a distribution with cdf $F(x)$. Let
$$
F_n(u) = \frac{1}{n}\sum_{j=1}^nI(x_j\leq u)
$$
be the empirical distribution function based on the sample, where $I(\cdot)$ denotes the indicator function.

An estimator of the Gini ratio is
$$
\begin{aligned}
\hat G &= \frac{1}{2n^2\hat\mu}
\sum_{j=1}^n\sum_{i=1}^n|x_i-x_j|\\
&= \frac{1}{n^2\hat\mu}\sum_{i=1}^n(2i-n-1)x_{(i)}
\end{aligned}
$$
where $x_{(i)}$ is the order statistics of the sample, $\hat\mu=\bar x$ is the sample mean.

Let
$$
h(u_1,u_2) = I(u_2\leq u_1)u_1 + I(u_1\leq u_2)u_2
$$
For $u_1\geq 0$, let
$$
\begin{aligned}
h_1(u_1) &= {\rm E}[h(u_1,X)]\\
&= u_1F(u_1) + \int _{u_1}^\infty xdF(x)
\end{aligned}
$$
We have the following result on the asymptotic normality of $\hat G$:

Suppose that $0<{\rm E}[X^2]<\infty$. Then, as $n\to\infty$,
$$
\sqrt n(\hat G-G) \stackrel{d}{\longrightarrow}
{\rm N}(0,\sigma_1^2)
$$
where $\sigma_1^2=\mu^{-2}{\rm Var}(2h_1(X)-(G+1)X)$, and $\stackrel{d}{\longrightarrow}$ denotes convergence in distribution.

Hence, a $(1-\alpha)$-level normal approximation confidence interval on $G$ is given by
$$
\Bigg[
\hat G-z_{\alpha/2}\frac{\hat \sigma_1}{\sqrt{n}},\
\hat G+z_{\alpha/2}\frac{\hat \sigma_1}{\sqrt{n}}
\Bigg]
$$
where $z_{\alpha/2}$ is the upper $\alpha/2$ quantile from the standard normal distribution and
$$
\sigma_1^2 = \frac{1}{\hat\mu^2}\cdot
\frac{1}{n-1}\sum_{i=1}^n(u_{1i}-\bar u_1)^2
$$
with
$$
\begin{aligned}
u_{1i} &= 2\hat h_1(x) - (\hat G+1)x_i\\
\bar u_1 &= \frac{1}{n}\sum_{i=1}^nu_{1i}
\end{aligned}
$$
and
$$
\hat h(u) = uF_n(u) + \frac{1}{n}\sum_{j=1}^nx_jI(x_j\geq u)
$$

Reference: Qin Y , Rao J N K , Wu C . Empirical likelihood confidence intervals for the Gini measure of income inequality[J]. Economic Modelling, 2010, 27(6):0-1435.

```{r}
F_n <- function(u, x){
  n <- length(x)
  mean(x<=u)
}
h1.hat<- function(u, x){
  u*F_n(u, x) + mean(x*(x>=u))
}
set.seed(123)
G <- gini(rlnorm(1000000, meanlog = 0, sdlog = 1)) #as nominal value
n <- 50
alpha <- 0.05
calCI.G <- function(n, alpha){
  x <- rlnorm(n, meanlog = 0, sdlog = 1)
  mu.hat <- mean(x)
  G.hat <- gini(x)
  u1 <- numeric(n)
  for (i in 1:n){
    u1[i] <- 2*h1.hat(x[i], x) - (G.hat+1)*x[i]
  }
  sigma1 <- var(u1)*n/(n-1)
  sigma1 <- sqrt(sigma1)/mu.hat
  z <- qnorm(1-alpha/2) #Upper alpha/2 quantile
  z <- z*sigma1/sqrt(n)
  return (c(G.hat-z, G.hat+z))
}
m <- 1000
CI <- matrix(0, ncol = 2, nrow = m)
cnt <- 0
for (i in 1:m){
  CI[i,] <- calCI.G(n, alpha)
  if ((CI[i,1]<G) & (CI[i,2]>G)){
    cnt <- cnt + 1
  }
}
cnt/m
```

## 2
__Proof:__

$X_1,...,X_n$ are i.i.d. samples from a normal distribution $N(\mu,\sigma^2)$, $n\geq 2$. The sample mean is $\bar X=\sum_{i=1}^nX_i$. $\bar X$ follows a $N(\mu,\sigma^2/n)$ distribution. Then, 
$$\frac{\bar X-\mu}{\sigma/\sqrt{n}}$$
follows a $N(0,1)$  distribution, and 
$$
\frac{X_i-\mu}{\sigma},\ n=1,...n
$$
also follows a $N(0,1)$  distribution. Thus
$$
\bigg(\frac{\bar X-\mu}{\sigma/\sqrt{n}}\bigg)^2
$$
follows a $\chi^2(1)$ distribution, and 
$$
\sum_{i=1}^n\frac{(X_i-\mu)^2}{\sigma^2}
$$
follows a $\chi^2(n)$ distribution. 

Since
$$
\begin{aligned}
V &= \sum_{i=1}^n\frac{(X_i-\bar X)^2}{\sigma^2}\\
&= \frac{1}{\sigma^2}\sum_{i=1}^n
\bigg[(X_i-\mu)^2-\mu^2+\bar X^2-2X_i\bar X+2X_i\mu
\bigg]\\
&= \frac{1}{\sigma^2}\sum_{i=1}^n(X_i-\mu)^2+
\frac{1}{\sigma^2}\sum_{i=1}^n
\bigg[(\bar X^2-\mu^2)-2X_i(\bar X-\mu)
\bigg]\\
&= \frac{1}{\sigma^2}\sum_{i=1}^n(X_i-\mu)^2+
\frac{n}{\sigma^2}(\bar X-\mu)\bigg[
(\bar X+\mu)-\frac{2}{n}\sum_{i=1}^nX_i\bigg]\\
&= \frac{1}{\sigma^2}\sum_{i=1}^n(X_i-\mu)^2+
\frac{n}{\sigma^2}(\bar X-\mu)(\mu-\bar X)\\
&= \sum_{i=1}^n\frac{(X_i-\mu)^2}{\sigma^2}
- \bigg(\frac{\bar X-\mu}{\sigma/\sqrt{n}}\bigg)^2
\end{aligned}
$$
therefore $V$ follows a $\chi^2(n-1)$ distribution independent with the sample mean $\bar X$.
$\Box$

## 3
### (1)
If $X_1,...,X_n$ is a random sample from $N(\mu,\sigma^2)$ distribution, $n\geq 2$, and $S^2$ is the sample variance, then
$$
V = \frac{(n-1)S^2}{\sigma^2}\sim \chi^2(n-1)
$$
A new confidence interval using $\alpha/2$ and $(1-\alpha/2)$-quantiles of the same $\chi^2$ distribution can be a two side $100(1-\alpha)\%$ confidence interval:
$$
\bigg[
\frac{(n-1)S^2}{\chi^2_{1-\alpha/2}(n-1)},\
\frac{(n-1)S^2}{\chi^2_{\alpha/2}(n-1)}
\bigg]
$$
where $\chi^2_{\alpha}(n-1)$ denotes the lower $\alpha$-quantile of $\chi^2(n-1)$ distribution.

__Proof:__

$$
{\rm P}\bigg(\chi^2_{\alpha/2}(n-1)\leq V\leq \chi^2_{1-\alpha/2}(n-1)\bigg) = 1-\alpha
$$
i.e.,
$$
{\rm P}\bigg(
\frac{(n-1)S^2}{\chi^2_{1-\alpha/2}(n-1)}
\leq \sigma^2 \leq
\frac{(n-1)S^2}{\chi^2_{\alpha/2}(n-1)}
\bigg) = 1-\alpha
$$
therefore, the theoretical confidence level is $1-\alpha$.

### (2)
```{r}
#type 1
set.seed(123)
n <- 20
alpha <- 0.05
m <- 1000
calCI1 <- function(n, alpha){
  x <- rnorm(n, mean=0, sd=2)
  return ((n-1) * var(x)/qchisq(alpha, df = n-1))
}
UCL <- replicate(m, expr = {
  calCI1(n=n, alpha=alpha)
})
p1 <- mean(UCL > 4) #empirical coverage probability
w1 <- mean(UCL) #average conficence interval width
#type 2
calCI2 <- function(n, alpha){
  x <- rnorm(n, mean=0, sd=2)
  z1 <- (n-1) * var(x)/qchisq(alpha/2, df = n-1)
  z2 <- (n-1) * var(x)/qchisq(1-alpha/2, df = n-1)
  return (c(z2, z1))
}
CI <- matrix(0, ncol = 2, nrow = m)
cnt <- 0
for (i in 1:m){
  CI[i,] <- calCI2(n, alpha)
  if ((CI[i,1]<4) & (CI[i,2]>4)){
    cnt <- cnt + 1
  }
}
p2 <- cnt/m #empirical coverage probability
w2 <- mean(CI[,2]-CI[,1]) #average conficence interval width
cbind(c(p1,p2),c(w1,w2))
```

### (3)
```{r}
set.seed(123)
n <- 20
alpha <- 0.05
m <- 1000
calCI1 <- function(n, alpha){
  x <- rchisq(n, df=2)
  return ((n-1) * var(x)/qchisq(alpha, df = n-1))
}
UCL <- replicate(m, expr = {
  calCI1(n=n, alpha=alpha)
})
p1 <- mean(UCL > 4) #empirical coverage probability
w1 <- mean(UCL) #average conficence interval width
#type 2
calCI2 <- function(n, alpha){
  x <- rchisq(n, df=2)
  z1 <- (n-1) * var(x)/qchisq(alpha/2, df = n-1)
  z2 <- (n-1) * var(x)/qchisq(1-alpha/2, df = n-1)
  return (c(z2, z1))
}
CI <- matrix(0, ncol = 2, nrow = m)
cnt <- 0
for (i in 1:m){
  CI[i,] <- calCI2(n, alpha)
  if ((CI[i,1]<4) & (CI[i,2]>4)){
    cnt <- cnt + 1
  }
}
p2 <- cnt/m #empirical coverage probability
w2 <- mean(CI[,2]-CI[,1]) #average conficence interval width
cbind(c(p1,p2),c(w1,w2))
```

### (4)
In practice, I would recommend the new confidence interval, because it has a smaller average interval width so that we can make a more precise estimation for $\hat\sigma^2$.