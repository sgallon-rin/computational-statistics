---
title: "Homework 1"
author: "Shen Jialun 16307110030"
date: "10/02/2019"
output:
  pdf_document: default
  html_document: default
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 3.3

Let
$$ u = F(x) = 1- \bigg(\frac{b}{x}\bigg)^a ,\quad\quad\quad x\geq b>0, a>0 $$
then we can obtain
$$ x = \frac{b}{(1-u)^\frac{1}{a}} $$
thus
$$ F^{-1}(U)=\frac{b}{(1-U)^\frac{1}{a}} $$
In this case, $a=b=2$, take the derivative of $F(x)$, we get the p.d.f. of $X$
following Pareto(2,2) distribution:
$$f(x)=\frac{8}{x^3}$$
Since $U$ and $1-U$ follows the same distribition, we can simplify the simulation.
Take sample size $n=1000$.

```{r 3.3}
n <- 1000
u <- runif(n)
x <- 2/u^(1/2)
hist(x, prob = TRUE, breaks = 300, xlim = c(0,30), main = "")
y <- seq(2, 30, length.out = n)
lines(y, 8/y^3, lwd=1.5, col="red")
```


## 3.5

From the p.m.f., we can get the c.d.f. of $X$ is
$$
F(x)=\begin{cases}
0.1,\quad x=0\\
0.3,\quad x=1\\
0.5,\quad x=2\\
0.7,\quad x=3\\
1,\quad x=4
\end{cases}
$$
Thus, the inverse function is
$$
F^{-1}(u)=\begin{cases}
0,\quad u\leq 0.1\\
1,\quad 0.1<u\leq 0.3\\
2,\quad 0.3<u\leq 0.5\\
3,\quad 0.5<u\leq 0.7\\
4,\quad 0.7<u\leq 1
\end{cases}
$$
In the following relative frequency table, the 1st row is the empirical probability of $X$ generated using inverse transform method, the 2nd row is the empirical probability of $X$ generated by R smaple function, the 3rd row is the theoretical probability.

```{r 3.5}
n <- 1000
u <- runif(n)
x <- as.integer(u>0.1) + as.integer(u>0.3) + as.integer(u>0.5) + as.integer(u>0.7)
p <- c(.1, .2, .2, .2, .3)
y <- sample(c(0,1,2,3,4), size = n, replace = TRUE, prob = p)
round(rbind(table(x)/n, table(y)/n, p), 3)
```

## 3.6

__Proof:__

$1^{\circ}$ For the discrete case:

The probability of y being accepted given a certain $Y$ is
$$
{\rm P}({\rm accept}|Y) = {\rm P}\Bigg(U<\frac{f(Y)}{cg(Y)}\Bigg) = \frac{f(Y)}{cg(Y)}
$$

Applying the rule of total probability, we have
$$
\begin{aligned}
{\rm P}({\rm accept}) &= \sum_{y}{\rm P}({\rm accept}|Y=y){\rm P}(Y=y)\\
&= \sum_y\frac{f(y)}{cg(y)}g(y)\\
&= \frac{1}{c}\sum_yf(y)\\
&= \frac{1}{c}
\end{aligned}
$$

Thus
$$
\begin{aligned}
{\rm P}(X=y) &= {\rm P}(Y=y|{\rm accept})\\
&= \frac{{\rm P}({\rm accept}|Y=y){\rm P}(Y=y)}{{\rm P}({\rm accept})}\\
&= \frac{\frac{f(y)}{cg(y)}g(y)}{\frac{1}{c}}\\
&= f(y)
\end{aligned}
$$
i.e., accepted $Y$'s are a random sample from the target density $f_X$.

$2^{\circ}$ For the continuous case:

$$
\begin{aligned}
{\rm P}(X\leq y) &= {\rm P}(Y\leq y|{\rm accept})\\
&= \frac{{\rm P}({\rm accept},Y\leq y)}{{\rm P}({\rm accept})}\\
&= \frac{{\rm P}\Big(Y\leq y,U\leq \frac{f(Y)}{cg(Y)}\Big)}{\int^{+\infty}_{-\infty}\frac{f(y)}{cg(y)}g(y)dy}\\
&= \frac{\int_{-\infty}^y{\rm P}\bigg(U\leq\frac{f(Y)}{cg(Y)}\bigg|Y=\omega\leq y\bigg)g(\omega)d\omega}{1/c}\\
&= c\int_{-\infty}^y\frac{f(\omega)}{cg(\omega)}g(\omega)d\omega\\
&= F_X(y)
\end{aligned}
$$
i.e., accepted $Y$'s are a random sample from the target density $f_X$.
$\blacksquare$

## 3.7

The Beta(a,b) density is
$$
f_{a,b}(x) = \frac{1}{{\rm B}(a,b)}x^{a-1}(1-x)^{b-1},\quad 0<x<1,\quad a>0,b>0
$$
Let $g(x)=1$ be the Uniform(0,1) density. Then $f(x)/g(x)\leq 1/{\rm Beta(a,b)}$ 
for all $0<x<1$, so $c=1/{\rm Beta}(a,b)$. A random $x$ from $g(x)$ is accepted if
$$
\frac{f(x)}{cg(x)} = \frac{x^{a-1}(1-x)^{b-1}/{\rm Beta}(a,b)}{1/{\rm Beta}(a,b)}
= x^{a-1}(1-x)^{b-1} > u
$$

The function to generate a random sample of size $n$ from the ${\rm Beta}(a,b)$
distribution by the acceptance-rejection method is defined as

```{r 3.7-1}
nBetaAR <- function(n, a, b){
  k <- 0 #counter for accepted
  y <- numeric(n)
  c <- beta(a, b)
  while (k < n){
    u <- runif(1)
    x <- runif(1) #random variate from g
    if (x^(a-1) * (1-x)^(b-1) > u){
      #we accept x
      k <- k + 1
      y[k] <- x
    }
  }
  return (y)
}
```

Since
$$
{\rm B}(3,2)=\int_0^1x^{3-1}(1-x)^{2-1}dx=\frac{1}{12}
$$
Thus, the Beta(3,2) density is $f(x)=12x^2(1-x),\quad 0<x<1$.
Let $g(x)$ be the Uniform(0,1) density. Then $c=12$. 
A random $x$ from $g(x)$ is accepted if
$$
\frac{f(x)}{cg(x)} = x^2(1-x) > u
$$

A random sample of size $n=1000$ can be generated by the following code

```{r 3.7-2}
n <- 1000
x <- nBetaAR(n, 3, 2)
hist(x, prob = TRUE, breaks = 100, main = "", xlim = c(0, 1))
y <- seq(0, 1, length.out = n)
lines(y, y^2*(1-y)/beta(3,2), lwd=1.5, col="red")
```

A better simulation can be generated if we increase $n$, e.g., $n=10000$

```{r 3.7-3}
n <- 10000
x <- nBetaAR(n, 3, 2)
hist(x, prob = TRUE, breaks = 100, main = "", xlim = c(0, 1))
y <- seq(0, 1, length.out = n)
lines(y, y^2*(1-y)/beta(3,2), lwd=1.5, col="red")
```

## 3.12

```{r 3.12}
n <- 1000
r <- 4
beta <- 2
lambda <- rgamma(n, r, beta)
y <- rexp(n, lambda)
```


## 3.13

The mixture in Exercise 3.12 has a Pareto distribution with cdf
$$
F(y) = 1-\Bigg(\frac{\beta}{\beta +y}\Bigg)^r, \quad y\geq 0
$$

Thus $Y$ has pdf
$$
f(y) = F'(y) = \frac{r\beta^r}{(\beta +y)^{r+1}}, \quad y\geq 0
$$

```{r 3.13}
hist(y, prob = TRUE, breaks = 100, main = "", xlim = c(0, 10))
yy <- seq(0, 10, length.out = n)
lines(yy, 64/(2+yy)^5, lwd=1.5, col="red")
```


## 3.14

```{r 3.14}
n <- 200
mu <- c(0, 1, 2)
Sigma <- matrix(c(1, -.5, .5, -.5, 1, -.5, .5, -.5, 1), nrow = 3, ncol = 3)
rmvn.Choleski <-
  function(n, mu, Sigma) {
    # generate n random vectors from MVN(mu, Sigma)
    # dimension is inferred from mu and Sigma
    d <- length(mu)
    Q <- chol(Sigma) # Choleski factorization of Sigma
    Z <- matrix(rnorm(n*d), nrow=n, ncol=d)
    X <- Z %*% Q + matrix(mu, n, d, byrow=TRUE)
    X
  }
# generate the sample
X <- rmvn.Choleski(n, mu, Sigma)
pairs(X)
cor(X)
```

The location and correlatoion of each pair of variables 
approximately agree with the theoretical parameters of
the corresponding bivariate normal distribution.